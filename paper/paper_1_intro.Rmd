Following @camilli1992conceptual, we conceptualize differential item functioning (DIF) as a varying relationship between ability and probability of correct response for students from different groups that manifests when one imposes an item response model with too few ability dimensions. From this perspective, the term "differential item functioning" is, perhaps, a misnomer as DIF is better thought of as a property of the student, as opposed to the item. For example, @ackerman1992didactic describes a scenario in which a test intends to measure a student's math ability, but performance also depends on their verbal ability. In this case, math ability is the "target ability," and verbal ability is the "nuisance ability." Fitting a unidimensional item response model to this test results in students with low verbal ability receiving a score systematically lower than their true math ability; therein lies "DIF".

Despite this, the usual setup of DIF simulation studies frames DIF as a property of the item. For example, @kopf2015framework simulate students as belonging to either a reference or focal group. They fix the item easinesses for the reference group, ${b_j}^{\text{ref}}$, to values that they obtained from a previous study. They set item easinesses for the focal group to ${b_j}^{\text{foc}} = {b_j}^{\text{ref}}$ for items without DIF and ${b_j}^{\text{foc}} = {b_j}^{\text{ref}} - 0.6$ for items with DIF, where 0.6 is the magnitude of DIF in logits. They then simulate student ability ${\theta_i}^{\text{ref}} \sim N(0,1)$ for students in the reference group and ${\theta_i}^{\text{foc}} \sim N(-1,1)$ for students in the focal group. Finally, they generate item responses according to the Rasch model, which specifies that the probability of student $i$ responding correctly to item $j$ is
\begin{align}
P(y_{ij} = 1 | \theta_i, b_j) = \sigma(\theta_i + b_j) \label{zopf}
\end{align}
where $\sigma(x) = \frac{e^x}{e^x + 1}$ is the standard logistic function.

<!-- future improvement would be 1) show that for some student they equal just to make it ultra clear and 2) note that there are infinite possibilities the key is that the second term is -0.6 for students from the focal group -->

For every DIF simulation study framed in terms of item parameters that vary across groups, there is a mathematically equivalent setup in which students' abilities are multidimensional. For example, to translate the @kopf2015framework simulation from the DIF-as-item-property to the DIF-as-student-property view, item easiness is set to what was previously ${b_j}^{\text{ref}}$ for all students. Student ability is expanded to two dimensions, the target ability dimension and nuisance ability dimension. The target ability is the same as unidimensional ability above where ${\theta_i}^{\text{ref}} \sim N(0,1)$ for students in the reference group and ${\theta_i}^{\text{foc}} \sim N(-1,1)$ for students in the focal group. The nuisance ability takes one of two values: ${\eta_i}^{\text{ref}} = 0$ for students in the reference group and ${\eta_i}^{\text{foc}} = -1$ for students in the focal group. We then reply on a 2PL compensatory 2PL model; slopes on the target ability are $a_{1j} = 1$ for all items (consistent with the Rasch model) and the slope on nuisance ability is $a_{2j} = 0.6$ for all items with DIF, and $a_{2j} = 0$ otherwise. Again, 0.6 is the magnitude of DIF in logits. According to the two-dimensional compensatory 2PL model [@thissen1986taxonomy], the probability that student $i$ responds correctly to item $j$ is
\begin{align}
\text{Pr}(y_{ij} = 1 | \theta_i, \eta_i, a_{1j}, a_{2j}, b_j) = \sigma(a_{1j}\theta_i + a_{2j}\eta_i + b_j).
\end{align}
For a choice of student (from the focal or reference group) and item (with DIF or without), this model produces identical probabilities as Eqn \ref{zopf}. This translation between views makes explicit that nearly all DIF simulation studies have, perhaps suboptimally, examined the unrealistic scenario in which there is no variation in the nuisance ability for students in the same group.

<!-- i might be a bit share on this here. it's basically do you have a q matrix you believe in. there must be some work with cross-validating different q matrices and then believing that. klint said he had some ideas here too. maybe things to think about in the future -->

If we insist on describing simulation conditions from the DIF-as-student-property view, one might wonder the following: Why not fit a multidimensional item response model which describes the data fully instead of looking for bias in a lower dimensional model? @camilli1992conceptual tested this idea with the goal of a "more satisfying description of the secondary abilities" [p. 144]. He found that the rotational indeterminacy of item response models is challenging to overcome and concluded that "a priori knowledge of the true factor structure" is necessary [p. 144]. It's hard to imagine how one would have such knowledge. Therefore, the best approach, which the DIF literature has nearly unanimously taken, is to fit unidimensional item response models and then look for bias manifesting in the item parameters. This approach depends upon a crucial identifying assumption; this assumption is the target of our investigation.
