Inspired by @camilli1992conceptual, we view differential item functioning (DIF) as bias against a group of students that manifests when an item response model with too few ability dimensions is imposed. From this perspective, the term "differential item functioning" is, perhaps, a misnomer as DIF is a property of the student, not the item. For example, @ackerman1992didactic describes a scenario in which a test intends to measure a student's math ability, but performance also depends on their verbal ability. In this case, math ability is the "target ability," and verbal ability is the "nuisance ability." Fitting a unidimensional item response model to this test results in students with low verbal ability receiving a score systematically lower than their true math ability; therein lies the DIF.

Contrarily, the usual setup of DIF simulation studies frames DIF as a property of the item. For example, @kopf2015framework simulate students as belonging to either a reference or focal group. They fix the item difficulties for the reference group, ${b_j}^{\text{ref}}$, to values from a previous study. They set item difficulties for the focal group to ${b_j}^{\text{foc}} = {b_j}^{\text{ref}}$ for items without DIF and ${b_j}^{\text{foc}} = {b_j}^{\text{ref}} + 0.6$ for items with DIF, where 0.6 is the magnitude of DIF in logits. They simulate student ability ${\theta_i}^{\text{ref}} \sim N(0,1)$ for students in the reference group and ${\theta_i}^{\text{foc}} \sim N(-1,1)$ for students in the focal group and generate item responses according to the Rasch model. The Rasch model specifies that the probability of student $i$ responding correctly to item $j$ is
\begin{align}
    P(y_{ij} = 1 | \theta_i, b_j) = \sigma(\theta_i - b_j)
\end{align}
where $\sigma(x) = \frac{e^x}{e^x + 1}$ is the standard logistic function.

We find it more informative to describe simulation conditions in terms of single-dimensional items and multidimensional abilities. For example, to translate the @kopf2015framework simulation from the DIF-as-item-property view to the DIF-as-student-property view, item difficulty is set to what was previously ${b_j}^{\text{ref}}$ for all students. Student ability is expanded to two dimensions, the target ability dimension and nuisance ability dimension. The target ability is what was previously just ability where ${\theta_i}^{\text{ref}} \sim N(0,1)$ for students in the reference group and ${\theta_i}^{\text{foc}} \sim N(-1,1)$ for students in the focal group. The nuisance ability is set to ${\eta_i}^{\text{ref}} = 0$ for the reference group and ${\eta_i}^{\text{ref}} = -1$ for the focal group. We now need to use a 2PL model where the slope on target ability $a_{1j} = 1$ for all items (consistent with the Rasch model) and the slope on nuisance ability $a_{2j} = 0.6$ for all items with DIF and $a_{2j} = 0$ otherwise. Again, 0.6 is the magnitude of DIF in logits. According to the two-dimensional 2PL model, the probability student $i$ responding correctly to item $j$ is
\begin{align}
    P(y_{ij} = 1 | \theta_i, \eta_i, a_{1j}, a_{2j}, b_j) = \sigma(a_{1j}\theta_i + a_{2j}\eta_i - b_j).
\end{align}
This translation between views makes explicit that nearly all DIF simulation studies have, perhaps suboptimally, examined the unrealistic scenario in which the variance of the nuisance ability is set to 0 for all students in the same group.

If we insist on describing simulation conditions from the DIF-as-student-property view, one might wonder the following: Why not fit a multidimensional item response model which describes the data fully instead of looking for bias in a lower-than-necessary dimensional model? @camilli1992conceptual [p. 144] tested this idea with the goal of a "more satisfying description of the secondary abilities." He found that the rotational indeterminacy of item response models is challenging to overcome and concluded that "a priori knowledge of the true factor structure" is necessary. It's hard to imagine how one would have such knowledge. Therefore, the best approach, which the DIF literature has nearly unanimously taken, is to fit unidimensional item response models and then look for bias manifesting in the item parameters.
